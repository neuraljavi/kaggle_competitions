{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a6c0e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: catboost in e:\\kaggle\\.venv\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: pytorch-tabnet in e:\\kaggle\\.venv\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: graphviz in e:\\kaggle\\.venv\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in e:\\kaggle\\.venv\\lib\\site-packages (from catboost) (3.10.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in e:\\kaggle\\.venv\\lib\\site-packages (from catboost) (2.2.6)\n",
      "Requirement already satisfied: pandas>=0.24 in e:\\kaggle\\.venv\\lib\\site-packages (from catboost) (2.2.3)\n",
      "Requirement already satisfied: scipy in e:\\kaggle\\.venv\\lib\\site-packages (from catboost) (1.15.3)\n",
      "Requirement already satisfied: plotly in e:\\kaggle\\.venv\\lib\\site-packages (from catboost) (6.1.2)\n",
      "Requirement already satisfied: six in e:\\kaggle\\.venv\\lib\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: scikit_learn>0.21 in e:\\kaggle\\.venv\\lib\\site-packages (from pytorch-tabnet) (1.6.1)\n",
      "Requirement already satisfied: torch>=1.3 in e:\\kaggle\\.venv\\lib\\site-packages (from pytorch-tabnet) (2.7.1+cu126)\n",
      "Requirement already satisfied: tqdm>=4.36 in e:\\kaggle\\.venv\\lib\\site-packages (from pytorch-tabnet) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\kaggle\\.venv\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\kaggle\\.venv\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\kaggle\\.venv\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\kaggle\\.venv\\lib\\site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\kaggle\\.venv\\lib\\site-packages (from scikit_learn>0.21->pytorch-tabnet) (3.6.0)\n",
      "Requirement already satisfied: filelock in e:\\kaggle\\.venv\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in e:\\kaggle\\.venv\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in e:\\kaggle\\.venv\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (1.14.0)\n",
      "Requirement already satisfied: networkx in e:\\kaggle\\.venv\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in e:\\kaggle\\.venv\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (3.1.6)\n",
      "Requirement already satisfied: fsspec in e:\\kaggle\\.venv\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (2025.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\kaggle\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
      "Requirement already satisfied: colorama in e:\\kaggle\\.venv\\lib\\site-packages (from tqdm>=4.36->pytorch-tabnet) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\kaggle\\.venv\\lib\\site-packages (from jinja2->torch>=1.3->pytorch-tabnet) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\kaggle\\.venv\\lib\\site-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\kaggle\\.venv\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\kaggle\\.venv\\lib\\site-packages (from matplotlib->catboost) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\kaggle\\.venv\\lib\\site-packages (from matplotlib->catboost) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\kaggle\\.venv\\lib\\site-packages (from matplotlib->catboost) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in e:\\kaggle\\.venv\\lib\\site-packages (from matplotlib->catboost) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\kaggle\\.venv\\lib\\site-packages (from matplotlib->catboost) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in e:\\kaggle\\.venv\\lib\\site-packages (from plotly->catboost) (1.41.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"%pip install --quiet --upgrade pip\n",
    "!pip uninstall -y numpy && pip install \"numpy<2.0\"\n",
    "%pip install scikit-learn xgboost shap optuna\n",
    "%pip install skorch optuna scikit-learn xgboost\n",
    "%pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\"\"\"\n",
    "%pip install catboost pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e70ae989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Kaggle\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa: F401\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor, GradientBoostingClassifier, RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier  # :contentReference[oaicite:2]{index=2}\n",
    "\n",
    "from skorch import NeuralNetBinaryClassifier\n",
    "from skorch.callbacks import EarlyStopping\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3434c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga tus CSV ya procesados\n",
    "train = pd.read_csv(\"../data/train_final.csv\")\n",
    "test  = pd.read_csv(\"../data/test_final.csv\")\n",
    "\n",
    "\n",
    "ID_COLS  = [\"PassengerId\", \"Name\"]          # no entran al modelo\n",
    "TARGET   = \"Transported\"                    # 0 / 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8033604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 1.1 – Columnas numéricas “continuas”\n",
    "num_cont = [\n",
    "    \"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\",\n",
    "    \"Spa\", \"VRDeck\", \"CabinNum\", \"CabinNum_scaled\",\n",
    "    \"TotalSpent\"\n",
    "]\n",
    "\n",
    "# 🔍 1.2 – Enteros / ordinales a imputar con moda\n",
    "num_cat_int = [\"CabinDeck\", \"CabinSide\", \"Group\"]\n",
    "\n",
    "# 🔍 1.3 – Booleanos (0/1) – también modo\n",
    "num_bool = [\n",
    "    \"HomePlanet_Europa\", \"HomePlanet_Mars\",\n",
    "    \"CryoSleep_True\",\n",
    "    \"Destination_PSO J318.5-22\", \"Destination_TRAPPIST-1e\",\n",
    "    \"VIP\", \"HasSpent\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d5b5cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2) Imputadores y escalador robusto\n",
    "iter_imp = IterativeImputer(\n",
    "    estimator=ExtraTreesRegressor(n_estimators=40, max_depth=8, random_state=42),\n",
    "    max_iter=10,\n",
    "    initial_strategy='median',\n",
    "    random_state=42\n",
    ")  # Imputación iterativa para continuas :contentReference[oaicite:5]{index=5}\n",
    "\n",
    "mode_imp = SimpleImputer(strategy='most_frequent')  # moda para categóricas/booleanas\n",
    "\n",
    "# 2.3) ColumnTransformer con imputación y escalado\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num_cont\",   Pipeline([(\"imp\", iter_imp), (\"sc\", RobustScaler())]), num_cont),\n",
    "    (\"num_cat_int\", mode_imp, num_cat_int),\n",
    "    (\"num_bool\",    mode_imp, num_bool)\n",
    "], remainder=\"drop\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0220b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[TARGET].astype(\"float32\")\n",
    "X = train.drop(columns=ID_COLS + [TARGET])\n",
    "\n",
    "# Si por alguna razón se han quedado booleanos, pásalos a int\n",
    "bool_cols = X.select_dtypes(\"bool\").columns\n",
    "X[bool_cols] = X[bool_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ce9e1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb4177a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Red totalmente densa (feedforward) con:\n",
    "      - n_layers ocultas\n",
    "      - hidden_units por capa\n",
    "      - dropout opcional\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, n_layers=2, hidden_units=128, dropout=0.0):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        for _ in range(n_layers):\n",
    "            layers += [\n",
    "                nn.Linear(in_dim, hidden_units),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ]\n",
    "            in_dim = hidden_units\n",
    "        layers.append(nn.Linear(in_dim, 1))  # salida de logits\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X.float()).squeeze(1)  # logits sin sigmoid\n",
    "\n",
    "def make_dnn(trial):\n",
    "    \"\"\"\n",
    "    Construye un NeuralNetBinaryClassifier con:\n",
    "      - BCEWithLogitsLoss\n",
    "      - EarlyStopping de Skorch\n",
    "      - Optimizer Adam\n",
    "    \"\"\"\n",
    "    n_layers = trial.suggest_int(\"pt_layers\", 1, 10)\n",
    "    hid_units = trial.suggest_int(\"pt_units\", 64, 2048, step=32)\n",
    "    dropout = trial.suggest_float(\"pt_dropout\", 0.0, 0.5)\n",
    "    lr = trial.suggest_float(\"pt_lr\", 1e-8, 1e-2, log=True)\n",
    "    batch = trial.suggest_categorical(\"pt_batch\", [16, 32, 64, 128, 256, 512])\n",
    "\n",
    "    return NeuralNetBinaryClassifier(\n",
    "        module=DenseNet,\n",
    "        module__input_dim=len(num_cont) + len(num_cat_int) + len(num_bool),\n",
    "        module__n_layers=n_layers,\n",
    "        module__hidden_units=hid_units,\n",
    "        module__dropout=dropout,\n",
    "        lr=lr,\n",
    "        batch_size=batch,\n",
    "        max_epochs=800,  # tope razonable por fold\n",
    "        optimizer=torch.optim.Adam,\n",
    "        criterion=nn.BCEWithLogitsLoss,  # más estable que BCELoss + sigmoid \n",
    "        callbacks=[EarlyStopping(patience=15, monitor=\"valid_loss\", lower_is_better=True)],\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        verbose=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ea5adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tabnet(trial):\n",
    "    \"\"\"\n",
    "    Construye un TabNetClassifier. \n",
    "    NOTA: los parámetros de early stopping (max_epochs, patience) se pasan al fit(), no al constructor.\n",
    "    \"\"\"\n",
    "    return TabNetClassifier(\n",
    "        # ───────────────────────────── Arquitectura ────────────────────────────\n",
    "        n_d=trial.suggest_int(\"tn_nd\", 8, 32, step=8),\n",
    "        n_a=trial.suggest_int(\"tn_na\", 8, 32, step=8),\n",
    "        n_steps=trial.suggest_int(\"tn_steps\", 3, 8),\n",
    "        gamma=trial.suggest_float(\"tn_gamma\", 1.0, 2.0),\n",
    "        lambda_sparse=trial.suggest_float(\"tn_sparse\", 1e-5, 1e-3, log=True),\n",
    "\n",
    "        # ─────────────────────── Optimizer y Scheduler ───────────────────────\n",
    "        optimizer_fn=torch.optim.Adam,\n",
    "        optimizer_params=dict(lr=trial.suggest_float(\"tn_lr\", 1e-8, 1e-2, log=True)),\n",
    "        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "        scheduler_params=dict(gamma=0.95, step_size=10),\n",
    "\n",
    "        # ───────────────────────────── Otros ─────────────────────────────\n",
    "        seed=42,\n",
    "        verbose=0,\n",
    "        device_name=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66bc6c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_catboost(trial):\n",
    "    return CatBoostClassifier(\n",
    "        iterations=trial.suggest_int(\"cb_iter\", 200, 1000),\n",
    "        learning_rate=trial.suggest_float(\"cb_lr\", 1e-6, 0.1, log=True),\n",
    "        depth=trial.suggest_int(\"cb_depth\", 4, 16),\n",
    "        l2_leaf_reg=trial.suggest_float(\"cb_l2\", 1.0, 10.0, log=True),\n",
    "        eval_metric=\"Accuracy\",  # CatBoost maneja la métrica internamente\n",
    "        random_seed=42,\n",
    "        verbose=False,\n",
    "    )  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc9b2ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # 4.1) Sugerir el modelo a usar (espacio de búsqueda fijo)\n",
    "    model_name = trial.suggest_categorical(\n",
    "        \"model\", [\"GradientBoosting\", \"RandomForest\", \"XGBoost\", \"CatBoost\", \"TabNet\", \"DNN_PT\"]\n",
    "    )  # :contentReference[oaicite:16]{index=16}\n",
    "\n",
    "    # 4.2) Sugerir hiperparámetros del modelo ANTES del bucle de CV (espacio estático)\n",
    "    # ────────────────────────────────────────────────────────────────────────────\n",
    "    if model_name == \"GradientBoosting\":\n",
    "        gb_n_estimators = trial.suggest_int(\"gb_n_estimators\", 100, 800)\n",
    "        gb_lr = trial.suggest_float(\"gb_lr\", 0.01, 0.2, log=True)\n",
    "        gb_max_depth = trial.suggest_int(\"gb_max_depth\", 2, 5)\n",
    "        gb_subsample = trial.suggest_float(\"gb_subsample\", 0.6, 1.0)\n",
    "        model = GradientBoostingClassifier(\n",
    "            random_state=42,\n",
    "            n_estimators=gb_n_estimators,\n",
    "            learning_rate=gb_lr,\n",
    "            max_depth=gb_max_depth,\n",
    "            subsample=gb_subsample\n",
    "        )\n",
    "\n",
    "    elif model_name == \"RandomForest\":\n",
    "        rf_n_estimators = trial.suggest_int(\"rf_n_estimators\", 200, 1000)\n",
    "        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 4, 20)\n",
    "        rf_split = trial.suggest_int(\"rf_split\", 2, 10)\n",
    "        rf_leaf = trial.suggest_int(\"rf_leaf\", 1, 5)\n",
    "        rf_feats = trial.suggest_categorical(\"rf_feats\", [\"sqrt\", \"log2\", None])\n",
    "        model = RandomForestClassifier(\n",
    "            random_state=42, n_jobs=-1,\n",
    "            n_estimators=rf_n_estimators,\n",
    "            max_depth=rf_max_depth,\n",
    "            min_samples_split=rf_split,\n",
    "            min_samples_leaf=rf_leaf,\n",
    "            max_features=rf_feats\n",
    "        )\n",
    "\n",
    "    elif model_name == \"XGBoost\":\n",
    "        xgb_n_estimators = trial.suggest_int(\"xgb_n_estimators\", 300, 1200)\n",
    "        xgb_lr = trial.suggest_float(\"xgb_lr\", 1e-8, 0.2, log=True)\n",
    "        xgb_max_depth = trial.suggest_int(\"xgb_max_depth\", 3, 20)\n",
    "        xgb_subsample = trial.suggest_float(\"xgb_subsample\", 0.6, 1.0)\n",
    "        xgb_colsample = trial.suggest_float(\"xgb_colsample\", 0.5, 1.0)\n",
    "        xgb_gamma = trial.suggest_float(\"xgb_gamma\", 0, 10)\n",
    "        xgb_l2 = trial.suggest_float(\"xgb_l2\", 1e-6, 10, log=True)\n",
    "        model = XGBClassifier(\n",
    "            objective=\"binary:logistic\",\n",
    "            eval_metric=\"logloss\",\n",
    "            n_jobs=1,\n",
    "            random_state=42,\n",
    "            n_estimators=xgb_n_estimators,\n",
    "            learning_rate=xgb_lr,\n",
    "            max_depth=xgb_max_depth,\n",
    "            subsample=xgb_subsample,\n",
    "            colsample_bytree=xgb_colsample,\n",
    "            gamma=xgb_gamma,\n",
    "            reg_lambda=xgb_l2,\n",
    "            tree_method=\"hist\",\n",
    "            device=\"cpu\"  # Cambia a \"cuda\" si tienes GPU\n",
    "        )\n",
    "\n",
    "    elif model_name == \"CatBoost\":\n",
    "        model = make_catboost(trial)  # CatBoost sugiere internamente sus hiperparámetros\n",
    "\n",
    "    elif model_name == \"TabNet\":\n",
    "        tn_max_epochs = trial.suggest_int(\"tn_max_epochs\", 50, 1000)\n",
    "        tn_patience = trial.suggest_int(\"tn_patience\", 10, 50)\n",
    "        model = make_tabnet(trial)\n",
    "\n",
    "    else:  # DNN_PT\n",
    "        model = make_dnn(trial)\n",
    "\n",
    "    # 4.3) Validación cruzada manual (5 folds estratificados)\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_train_fold = X.iloc[train_idx]\n",
    "        y_train_fold = y.iloc[train_idx]\n",
    "        X_val_fold = X.iloc[val_idx]\n",
    "        y_val_fold = y.iloc[val_idx]\n",
    "\n",
    "        # Definir pipeline con preprocesamiento + modelo\n",
    "        pipe = Pipeline([(\"prep\", preprocess), (\"clf\", model)])\n",
    "\n",
    "        if model_name == \"TabNet\":\n",
    "            # 4.4) Early stopping y evaluación en cada fold para TabNet\n",
    "            X_val_trans = pipe.named_steps[\"prep\"].transform(X_val_fold)\n",
    "            pipe.fit(\n",
    "                X_train_fold, y_train_fold,\n",
    "                **{\n",
    "                    \"clf__eval_set\": [(X_val_trans, y_val_fold.to_numpy())],\n",
    "                    \"clf__eval_name\": [\"val\"],\n",
    "                    \"clf__eval_metric\": [\"accuracy\"],\n",
    "                    \"clf__max_epochs\": tn_max_epochs,\n",
    "                    \"clf__patience\": tn_patience,\n",
    "                }\n",
    "            )\n",
    "            preds = pipe.predict(X_val_fold)\n",
    "            score = accuracy_score(y_val_fold, preds)\n",
    "\n",
    "        elif model_name == \"DNN_PT\":\n",
    "            # 4.5) Skorch ya tiene EarlyStopping configurado en make_dnn\n",
    "            pipe.fit(X_train_fold, y_train_fold)\n",
    "            preds = pipe.predict(X_val_fold)\n",
    "            score = accuracy_score(y_val_fold, preds)\n",
    "\n",
    "        else:\n",
    "            # 4.6) Modelos de árboles y boosting sin early stopping interno\n",
    "            pipe.fit(X_train_fold, y_train_fold)\n",
    "            preds = pipe.predict(X_val_fold)\n",
    "            score = accuracy_score(y_val_fold, preds)\n",
    "\n",
    "        fold_scores.append(score)\n",
    "\n",
    "    return np.mean(fold_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b3b110",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-05 00:43:20,805] Using an existing study with name 'titanic_optimization_v2' instead of creating a new one.\n",
      "  0%|          | 0/2000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# 7.1) Configurar Optuna para guardar en SQLite (opcional)\n",
    "# El parámetro \"storage\" permite recuperar resultados entre sesiones.\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\", \n",
    "    storage=\"sqlite:///optuna.db\", \n",
    "    load_if_exists=True, \n",
    "    study_name=\"titanic_optimization_v2\"\n",
    ")\n",
    "\n",
    "# 7.2) Lanzar la optimización (p. ej. 200 trials para demo; aumenta a 1000+ si tienes tiempo)\n",
    "study.optimize(objective, n_trials=2000, show_progress_bar=True)\n",
    "\n",
    "# 7.3) Resultados\n",
    "print(f\"Best trial: {study.best_trial.number}\")\n",
    "print(f\"Best value: {study.best_trial.value:.5f}\")\n",
    "print(\"Best params:\")\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f4ae05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor accuracy: 0.8164036180734268\n",
      "Mejores params: {'model': 'CatBoost', 'cb_iter': 631, 'cb_lr': 0.023321158701556228, 'cb_depth': 7, 'cb_l2': 3.4047591260661614}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32me:\\Kaggle\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'params'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Tabla comparativa por modelo\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df_hist \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mtrials_dataframe(attrs\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m----> 6\u001b[0m df_hist[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_hist\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m d: d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_hist\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39magg([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "File \u001b[1;32me:\\Kaggle\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32me:\\Kaggle\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'params'"
     ]
    }
   ],
   "source": [
    "print(\"Mejor accuracy:\", study.best_value)\n",
    "print(\"Mejores params:\", study.best_params)\n",
    "\n",
    "# Tabla comparativa por modelo\n",
    "df_hist = study.trials_dataframe(attrs=(\"value\",\"params\"))\n",
    "df_hist[\"model\"] = df_hist[\"params\"].apply(lambda d: d[\"model\"])\n",
    "print(df_hist.groupby(\"model\")[\"value\"].agg([\"count\",\"max\",\"mean\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1811919",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = study.best_params\n",
    "model_name = best.pop(\"model\")\n",
    "\n",
    "if model_name == \"GradientBoosting\":\n",
    "    best_model = GradientBoostingClassifier(random_state=42, **{\n",
    "        k.split(\"gb_\")[1]: v for k, v in best.items()\n",
    "    })\n",
    "elif model_name == \"RandomForest\":\n",
    "    best_model = RandomForestClassifier(random_state=42, n_jobs=-1, **{\n",
    "        k.split(\"rf_\")[1]: v for k, v in best.items()\n",
    "    })\n",
    "elif model_name == \"DNN_PT\":\n",
    "    best_model = NeuralNetClassifier(\n",
    "        module=DenseNet,\n",
    "        module__input_dim=X.shape[1],\n",
    "        module__n_layers=best[\"pt_layers\"],\n",
    "        module__hidden_units=best[\"pt_units\"],\n",
    "        module__dropout=best[\"pt_dropout\"],\n",
    "        max_epochs=50,\n",
    "        lr=best[\"pt_lr\"],\n",
    "        batch_size=best[\"pt_batch\"],\n",
    "        optimizer=torch.optim.Adam,\n",
    "        criterion=nn.BCELoss,\n",
    "        callbacks=[EarlyStopping(patience=5, monitor=\"valid_loss\",\n",
    "                                 lower_is_better=True)],\n",
    "        device=\"cuda\",\n",
    "        verbose=0\n",
    "    )\n",
    "else:\n",
    "    best_model = XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"logloss\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "        **{k.split(\"xgb_\")[1]: v for k, v in best.items()}\n",
    "    )\n",
    "\n",
    "final_pipe = Pipeline([(\"prep\", preprocess),\n",
    "                       (\"clf\",  best_model)])\n",
    "final_pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a118360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "names_cont = num_cont\n",
    "names_bool = num_bool\n",
    "feat_names = names_cont + names_bool\n",
    "\n",
    "importances = final_pipe[\"clf\"].feature_importances_\n",
    "pd.Series(importances, index=feat_names).sort_values().tail(15).plot.barh()\n",
    "plt.title(f\"Top features – {model_name}\"); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c2cecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(columns=ID_COLS)\n",
    "preds   = (final_pipe.predict_proba(X_test)[:,1] >= 0.5).astype(bool)\n",
    "pd.DataFrame({\"PassengerId\": test[\"PassengerId\"],\n",
    "              \"Transported\": preds}).to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
